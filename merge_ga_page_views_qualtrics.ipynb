{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Pandas is an open source library providing high-performance, easy-to-use data structures and data analysis tools for Python\n",
    "import json # JSON encoder and decoder for Python\n",
    "import re\n",
    "from functools import reduce\n",
    "import numpy as np\n",
    "from math import isnan\n",
    "from anonymizeip import anonymize_ip"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note it is possible that there are different Response IDs with the same IP address\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualtrics_data = pd.read_csv(\"C:/Users/huixin/Dropbox/research/menoplan/beta_phase/qualtrics_data/numeric_20oct.csv\")\n",
    "ga_data = pd.read_csv(\"C:/Users/huixin/Dropbox/research/menoplan/beta_phase/ga_data/20oct_page_visited.csv\")\n",
    "#click_event_data = pd.read_csv(\"C:/Users/huixin/Dropbox/research/menoplan/beta_phase/ga_data/20oct_events.csv\")\n",
    "qualtrics_data = qualtrics_data.iloc[2: , :]\n",
    "click_event_data = click_event_data.drop(columns=['Event Value', 'Avg. Value'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "qualtrics_data['EndDate']\n",
    "qualtrics_data['Date'] = pd.to_datetime(qualtrics_data['EndDate']).dt.date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ga_data = ga_data.rename(columns={'IP Address': 'IPAddress'})\n",
    "ga_data.head(4)\n",
    "ga_data.loc[ga_data['Page'] == '/', 'Page'] = 'homepage'\n",
    "ga_data['Page'] = ga_data['Page'].str.strip(\"/\")\n",
    "ga_data = ga_data.drop(columns=\"Page Value\")\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = (qualtrics_data['Date'] > pd.to_datetime(\"2021-09-23\").date()) #filter out dates on 23 Sept and before\n",
    "qualtrics_data = qualtrics_data[mask] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 431 unique response Ids but only 305 unique IP addresses.\n",
    "That means people are starting new qualtrics surveys from the same device. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Page', 'IPAddress', 'Pageviews', 'Unique Pageviews',\n",
       "       'Avg. Time on Page', 'Entrances', 'Bounce Rate', '% Exit', 'StartDate',\n",
       "       'EndDate', 'Status', 'Progress', 'Duration (in seconds)', 'Finished',\n",
       "       'RecordedDate', 'ResponseId', 'RecipientLastName', 'RecipientFirstName',\n",
       "       'RecipientEmail', 'ExternalReference', 'LocationLatitude',\n",
       "       'LocationLongitude', 'DistributionChannel', 'UserLanguage',\n",
       "       'Q_RecaptchaScore', 'Q2', 'Q30_First Click', 'Q30_Last Click',\n",
       "       'Q30_Page Submit', 'Q30_Click Count', 'Q4', 'Q5', 'Q6', 'Q7', 'Q8',\n",
       "       'Q9', 'Q10', 'Q11', 'Q12', 'Q13_1', 'Q13_2', 'Q13_3', 'Q13_4', 'Q13_5',\n",
       "       'Q13_6', 'Q14_1', 'Q14_2', 'Q14_3', 'Q14_4', 'Q14_5', 'Q14_6', 'Q15',\n",
       "       'Q16', 'Q17', 'Q18', 'Q19', 'Q20', 'Q21', 'Q22', 'Q23', 'Q24', 'Q25',\n",
       "       'Q27', 'Q28', 'Date'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = pd.merge(ga_data, qualtrics_data, on='IPAddress')\n",
    "merged_df.columns\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are 640 unique Response IDs but 415 unique IP addresses. What could lead to this discrepancy?\n",
    "In merged_df there are multiple rows for each uniqueIP because each row corresponds to a page visited"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "640 415\n"
     ]
    }
   ],
   "source": [
    "print(merged_df.ResponseId.nunique(), merged_df.IPAddress.nunique()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df.to_csv(\"merged_ga_qualtrics.csv\")\n",
    "merged_df = pd.read_csv(\"merged_ga_qualtrics.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewsPerPageById = merged_df.groupby(['ResponseId', 'Page'], as_index=False).agg({'Pageviews':'sum', 'StartDate':'first'})\n",
    "viewsPerPageById.columns = viewsPerPageById.columns.str.strip('/?=')\n",
    "viewsPerPageById= viewsPerPageById.rename(columns={\"\": \"homepage\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = list(viewsPerPageById.columns)\n",
    "r= re.compile('\\d*([.,\\/]?\\d+)')# use regex to find dates\n",
    "newlist = list(filter(r.match, ls)) # create list of dates \n",
    "viewsPerPageById = viewsPerPageById.drop(columns=newlist) #we do not want the dates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "insomnia_cols = [col for col in viewsPerPageById.columns if 'test/insomnia-severity-index' in col and len(col) >28]\n",
    "anxiety_cols = [col for col in viewsPerPageById.columns if 'test/anxiety-assessment' in col and len(col) >23]\n",
    "depression_cols = [col for col in viewsPerPageById.columns if 'test/depression-assessment' in col and len(col) >26]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewsPerPageById['insomnia-severity-index-results'] = viewsPerPageById[insomnia_cols].sum(axis=1)\n",
    "viewsPerPageById['anxiety-assessment-results'] = viewsPerPageById[anxiety_cols].sum(axis=1)\n",
    "viewsPerPageById['depression-assessment-results'] = viewsPerPageById[depression_cols].sum(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewsPerPageById = viewsPerPageById.drop(columns=insomnia_cols)\n",
    "viewsPerPageById = viewsPerPageById.drop(columns=anxiety_cols)\n",
    "viewsPerPageById = viewsPerPageById.drop(columns=depression_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['AllViewedPages']= merged_df[['ResponseId', 'EndDate','Page']].groupby(['ResponseId', 'EndDate'])['Page'].transform(lambda x: ','.join(x))\n",
    "merged_df[['ResponseId','EndDate','AllViewedPages']].drop_duplicates() #drop rows if allViewedPages, ResponseId and EndDate are the same\n",
    "merged_df.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "viewedPagesSummary = merged_df.groupby(['ResponseId','AllViewedPages'], as_index=False).agg({'Pageviews':'sum', 'Unique Pageviews':\"sum\"})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "viewedPagesSummary has ResponseId, all viewed pages, page views and unique page views."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# compile the list of dataframes you want to merge\n",
    "data_frames = [viewedPagesSummary,viewsPerPageById, qualtrics_data]\n",
    "df_merged = reduce(lambda  left,right: pd.merge(left,right,on=['ResponseId'], how='inner'), data_frames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_merged['IPFreq']=df_merged['IPAddress'].map(df_merged['IPAddress'].value_counts())\n",
    "df_merged = df_merged.sort_values(by=['IPFreq', 'IPAddress'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saved = df_merged\n",
    "df_saved_no_ip = df_saved.drop('IPAddress', axis=1)  #remove IPAddress column\n",
    "df_saved_no_ip.to_csv(\"C:/Users/huixin/Dropbox/research/menoplan/beta_phase/user_data_20oct_no_ip.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_saved.to_csv(\"C:/Users/huixin/Dropbox/research/menoplan/beta_phase/user_data_20oct.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dfByUser is a df with a single user as row. AllViewedPages is a list of all pages a used has visited. This df also unique page views and total page views. However, this df is not useful because it is merged with qualtrics data that has NOT been preprocessed by Leslie.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfByUser = pd.read_csv(\"C:/Users/huixin/Dropbox/research/menoplan/beta_phase/user_data_20oct.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dropNaCols = dfByUser.dropna(axis=1, how='all') #only these columns are all NAs\n",
    "#dfByUser.columns[dfByUser.isnull().all(0)] #'RecipientLastName', 'RecipientFirstName', 'RecipientEmail','ExternalReference'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
